# coding:utf-8
import os
import time
from datetime import datetime

import torch
from torch import nn
from torch.optim import Adam
import torch.nn.functional as F
from torch.utils.data import DataLoader
from torch.optim.lr_scheduler import StepLR
from tqdm import tqdm

from .dataset import SRDataset
from .network import SRNet


def exception_handler(train_func):
    """ å¤„ç†è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿçš„å¼‚å¸¸å¹¶ä¿å­˜æ¨¡åž‹ """
    def wrapper(train_pipeline, *args, **kwargs):
        try:
            return train_func(train_pipeline, *args, **kwargs)
        except KeyboardInterrupt:
            train_pipeline.save()
            exit()
    return wrapper


class SRNetLoss(nn.Module):
    """ SRNet çš„æŸå¤±å‡½æ•° """

    def __init__(self):
        super().__init__()

    def forward(self, M_hat, M, S_hat, S, D_hat, D):
        loss = F.mse_loss(D_hat, D) + F.mse_loss(S_hat, S) + \
            F.binary_cross_entropy(M_hat, M)
        return loss


class TrainPipeline:
    """ è®­ç»ƒæµæ°´çº¿ """

    def __init__(self, train_dataset_dir: str, test_dataset_dir: str, lr=0.01, step_size=10,
                 train_batch_size=10, test_batch_size=10, epochs=20, test_freq=5, use_gpu=True,
                 model_dir=None):
        """
        Parameters
        ----------
        train_dataset_dir: str
            è®­ç»ƒé›†æ–‡ä»¶å¤¹è·¯å¾„

        test_dataset_dir: str
            æµ‹è¯•é›†æ–‡ä»¶å¤¹è·¯å¾„

        lr: float
            å­¦ä¹ çŽ‡

        step_size: int
            å­¦ä¹ çŽ‡è¡°å‡çš„çš„æ­¥é•¿

        train_batch_size: int
            è®­ç»ƒé›† batch å¤§å°

        test_batch_size: int
            æµ‹è¯•é›† batch å¤§å°

        epochs: int
            ä¸–ä»£æ•°

        test_freq: int
            æµ‹è¯•é¢‘çŽ‡

        use_gpu: bool
            æ˜¯å¦ä½¿ç”¨ GPU

        model_dir: str
            æ¨¡åž‹ä¿å­˜æ–‡ä»¶å¤¹è·¯å¾„ï¼Œå¦‚æžœä¸º Noneï¼Œåˆ™ä¿å­˜åˆ° `'./model'`
        """
        self.lr = lr
        self.epochs = epochs
        self.test_freq = test_freq
        self.device = torch.device('cuda:0' if use_gpu else 'cpu')
        self.model = SRNet().to(self.device)
        self.model_dir = model_dir if model_dir else 'model'
        # åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
        self.train_dataset = SRDataset(train_dataset_dir)
        self.test_dataset = SRDataset(test_dataset_dir)
        self.train_loader = DataLoader(
            self.train_dataset, batch_size=train_batch_size, shuffle=True)
        self.test_loader = DataLoader(
            self.test_dataset, batch_size=test_batch_size, shuffle=True)
        # å®šä¹‰ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        self.criterion = SRNetLoss()
        self.optimizer = Adam(self.model.parameters(), lr=0.01)
        self.lr_scheduler = StepLR(
            optimizer=self.optimizer, step_size=step_size, gamma=0.1)

    def save(self):
        """ ä¿å­˜æ¨¡åž‹ """
        os.makedirs(self.model_dir, exist_ok=True)
        t = time.strftime('%Y-%m-%d_%H-%M-%S', time.localtime(time.time()))
        path = f'{self.model_dir}/SRNet_{t}.pth'
        self.model.eval()
        torch.save(self.model.state_dict(), path)
        print(f'ðŸŽ‰ å·²å°†å½“å‰æ¨¡åž‹ä¿å­˜åˆ° {os.path.join(os.getcwd(), path)}')

    @exception_handler
    def train(self):
        """ è®­ç»ƒæ¨¡åž‹ """
        train_losses = []
        test_losses = []
        bar_format = '{desc}{n_fmt:>4s}/{total_fmt:<4s}|{bar}|{postfix}'
        print('ðŸš€ å¼€å§‹è®­ç»ƒï¼')
        for e in range(self.epochs):
            with tqdm(self.train_loader, bar_format=bar_format) as train_bar:
                train_bar.set_description(f"\33[36mðŸŒŒ Epoch {e + 1:3d}")
                start_time = datetime.now()
                self.model.train()
                for I, M, S, D in self.train_loader:
                    I = I.to(self.device)
                    M = M.to(self.device)
                    S = S.to(self.device)
                    D = D.to(self.device)
                    M_hat, S_hat, D_hat = self.model(I)
                    self.optimizer.zero_grad()
                    train_loss = self.criterion(M_hat, M, S_hat, S, D_hat, D)
                    train_loss.backward()
                    self.optimizer.step()
                    cost_time = datetime.now() - start_time
                    train_bar.set_postfix_str(
                        f'è®­ç»ƒæŸå¤±ï¼š{train_loss.item():.5f}, æ‰§è¡Œæ—¶é—´ï¼š{cost_time}\33[0m')
                    train_bar.update()

            # æµ‹è¯•æ¨¡åž‹
            if (e+1) % self.test_freq == 0:
                with tqdm(self.test_loader, bar_format=bar_format) as test_bar:
                    test_bar.set_description('\33[35mðŸ›¸ æµ‹è¯•ä¸­')
                    start_time = datetime.now()
                    self.model.eval()
                    for I, M, S, D in self.test_loader:
                        I = I.to(self.device)
                        M = M.to(self.device)
                        S = S.to(self.device)
                        D = D.to(self.device)
                        M_hat, S_hat, D_hat = self.model(I)
                        test_loss = self.criterion(M_hat, M, S_hat, S, D_hat, D)
                        cost_time = datetime.now() - start_time
                        test_bar.set_postfix_str(
                            f'æµ‹è¯•æŸå¤±ï¼š{test_loss.item():.5f}, æ‰§è¡Œæ—¶é—´ï¼š{cost_time}\33[0m')
                        test_bar.update()

                test_losses.append(test_loss.item())
                self.save()

            # è®°å½•è¯¯å·®
            train_loss = train_loss.item()
            train_losses.append(train_loss)
            self.lr_scheduler.step()

        return train_losses, test_losses
